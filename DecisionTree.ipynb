{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7fe4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_percentage_error\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5c5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature = None, threshold = None, gini = None, leaf = None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.gini = gini\n",
    "        self.leaf = leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28bb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth=100, min_samples=2, ccp_alpha=0.0, regression=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.ccp_alpha = ccp_alpha\n",
    "        self.regression = regression\n",
    "        self.tree = None\n",
    "        self.feature_importances_ = None\n",
    "        self._y_type = None\n",
    "        self._num_all_samples = None\n",
    "\n",
    "    def _set_df_type(self, X, y, dtype):\n",
    "        \n",
    "        X = X.astype(dtype)\n",
    "        y = y.astype(dtype) if self.regression else y\n",
    "        self._y_dtype = y.dtype\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _purity(y):\n",
    "        unique_classes = np.unique(y)\n",
    "        return unique_classes.size == 1\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_leaf_node(node):\n",
    "        return not isinstance(node, dict)   #Если лист \n",
    "\n",
    "    \n",
    "    def _leaf_node(self, y):\n",
    "        class_index = 0\n",
    "        return np.mean(y) if self.regression else y.mode()[class_index]\n",
    "\n",
    "    \n",
    "    def _split_df(self, X, y, feature, threshold):\n",
    "        feature_values = X[feature]\n",
    "        left_indexes = X[feature_values <= threshold].index\n",
    "        right_indexes = X[feature_values > threshold].index\n",
    "        sizes = np.array([left_indexes.size, right_indexes.size])\n",
    "\n",
    "        return self._leaf_node(y) if any(sizes == 0) else left_indexes, right_indexes\n",
    "\n",
    "    @staticmethod\n",
    "    def _gini_impurity(y):\n",
    "        \n",
    "        _, counts_classes = np.unique(y, return_counts=True)\n",
    "        squared_probabilities = np.square(counts_classes / y.size)\n",
    "        gini_impurity = 1 - sum(squared_probabilities)\n",
    "        \n",
    "        return gini_impurity\n",
    "\n",
    "    @staticmethod\n",
    "    def _mse(y):\n",
    "        \n",
    "        return np.mean((y - y.mean()) ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def _cost_function(left_df, right_df, method):\n",
    "        \n",
    "        total_df_size = left_df.size + right_df.size\n",
    "        p_left_df = left_df.size / total_df_size\n",
    "        p_right_df = right_df.size / total_df_size\n",
    "        J_left = method(left_df)\n",
    "        J_right = method(right_df)\n",
    "        J = p_left_df*J_left + p_right_df*J_right\n",
    "        return J  # weighted Gini impurity or weighted mse (depends on a method)\n",
    "\n",
    "    def _node_error_rate(self, y, method):\n",
    "        if self._num_all_samples is None:\n",
    "            self._num_all_samples = y.size   # num samples of all dataframe\n",
    "        current_num_samples = y.size\n",
    "        \n",
    "        current_rate = method(y)\n",
    "        \n",
    "        return current_rate\n",
    "    \n",
    "    def _importance_calc(self, y, current_rate, min_J):\n",
    "        if self._num_all_samples is None:\n",
    "            self._num_all_samples = y.size\n",
    "        current_num_samples = y.size\n",
    "        \n",
    "        return current_num_samples / self._num_all_samples * (current_rate - min_J)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        features = X.columns\n",
    "        min_cost_function = np.inf\n",
    "        best_feature, best_threshold = None, None\n",
    "        method = self._mse if self.regression else self._gini_impurity\n",
    "\n",
    "        for feature in features:\n",
    "            unique_feature_values = np.unique(X[feature])\n",
    "\n",
    "            for i in range(1, len(unique_feature_values)):\n",
    "                current_value = unique_feature_values[i]\n",
    "                previous_value = unique_feature_values[i-1]\n",
    "                threshold = (current_value + previous_value) / 2\n",
    "                left_indexes, right_indexes = self._split_df(X, y, feature, threshold)\n",
    "                left_labels, right_labels = y.loc[left_indexes], y.loc[right_indexes]\n",
    "                current_J = self._cost_function(left_labels, right_labels, method)\n",
    "\n",
    "                if current_J <= min_cost_function:\n",
    "                    min_cost_function = current_J\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, min_cost_function\n",
    "\n",
    "    def _stopping_conditions(self, y, depth, n_samples):\n",
    "        return self._purity(y), depth == self.max_depth, n_samples < self.min_samples\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        current_num_samples = y.size\n",
    "        X, y = self._set_df_type(X, y, np.float64)\n",
    "        method = self._mse if self.regression else self._gini_impurity\n",
    "\n",
    "        if any(self._stopping_conditions(y, depth, current_num_samples)):\n",
    "            RTi = self._node_error_rate(y, method)   # leaf node error rate\n",
    "            leaf_node = Node(leaf=self._leaf_node(y), gini=RTi)\n",
    "            return leaf_node\n",
    "\n",
    "        best_feature, best_threshold, min_J = self._best_split(X, y)\n",
    "        Rt = self._node_error_rate(y, method) # decision node error rate\n",
    "        \n",
    "        if best_feature in self.feature_importances_.keys():\n",
    "            self.feature_importances_[best_feature] += self._importance_calc(y, Rt, min_J)\n",
    "        else:\n",
    "            self.feature_importances_[best_feature] = self._importance_calc(y, Rt, min_J)\n",
    "    \n",
    "        decision_node = Node(feature=best_feature, leaf=self._leaf_node(y), threshold=best_threshold, gini=Rt)\n",
    "\n",
    "        left_indexes, right_indexes = self._split_df(X, y, best_feature, best_threshold)\n",
    "        left_X, right_X = X.loc[left_indexes], X.loc[right_indexes]\n",
    "        left_labels, right_labels = y.loc[left_indexes], y.loc[right_indexes]\n",
    "\n",
    "        # recursive part\n",
    "        tree = {decision_node: []}\n",
    "        left_subtree = self._grow_tree(left_X, left_labels, depth+1)\n",
    "        right_subtree = self._grow_tree(right_X, right_labels, depth+1)\n",
    "\n",
    "        if left_subtree == right_subtree:\n",
    "            tree = left_subtree\n",
    "        else:\n",
    "            tree[decision_node].extend([left_subtree, right_subtree])\n",
    "\n",
    "        return tree\n",
    "    \n",
    "    #########################################################################################\n",
    "\n",
    "    def _tree_error_rate_info(self, tree, error_rates_list):\n",
    "        if self._is_leaf_node(tree):\n",
    "            #*_, leaf_error_rate = tree.split()\n",
    "            #print(tree)\n",
    "            leaf_error_rate = tree.gini\n",
    "            error_rates_list.append(np.float64(leaf_error_rate))\n",
    "        else:\n",
    "            decision_node = next(iter(tree))\n",
    "            left_subtree, right_subtree = tree[decision_node]\n",
    "            self._tree_error_rate_info(left_subtree, error_rates_list)\n",
    "            self._tree_error_rate_info(right_subtree, error_rates_list)\n",
    "\n",
    "        RT = sum(error_rates_list)   # total leaf error rate of a tree\n",
    "        num_leaf_nodes = len(error_rates_list)\n",
    "\n",
    "        return RT, num_leaf_nodes\n",
    "\n",
    "    @staticmethod\n",
    "    def _ccp_alpha_eff(decision_node_Rt, leaf_nodes_RTt, num_leafs):\n",
    "\n",
    "        return (decision_node_Rt - leaf_nodes_RTt) / (num_leafs - 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_in_dict(need, some_dict):\n",
    "        if not hasattr(some_dict, 'items'):\n",
    "            return True if need == some_dict else None\n",
    "        for key, value in some_dict.items():\n",
    "            if key == need:\n",
    "                return True\n",
    "            else:\n",
    "                if hasattr(value, 'items'):\n",
    "                    print(value)\n",
    "                    if paths(need, value):\n",
    "                        return True\n",
    "        \n",
    "                \n",
    "\n",
    "    def _find_weakest_node(self, tree, weakest_node_info):\n",
    "        if self._is_leaf_node(tree):\n",
    "            return tree\n",
    "\n",
    "        decision_node = next(iter(tree))\n",
    "        left_subtree, right_subtree = tree[decision_node]\n",
    "        decision_node_error_rate = decision_node.gini\n",
    "\n",
    "        Rt = np.float64(decision_node_error_rate)\n",
    "        RTt, num_leaf_nodes = self._tree_error_rate_info(tree, [])\n",
    "        ccp_alpha = self._ccp_alpha_eff(Rt, RTt, num_leaf_nodes)\n",
    "        decision_node_index, min_ccp_alpha_index = 0, 1\n",
    "\n",
    "        if ccp_alpha <= weakest_node_info[min_ccp_alpha_index]:\n",
    "            weakest_node_info[decision_node_index] = decision_node\n",
    "            weakest_node_info[min_ccp_alpha_index] = ccp_alpha\n",
    "\n",
    "        self._find_weakest_node(left_subtree, weakest_node_info)\n",
    "        self._find_weakest_node(right_subtree, weakest_node_info)\n",
    "\n",
    "        return weakest_node_info\n",
    "\n",
    "    def _prune_tree(self, tree, weakest_node):\n",
    "        if self._is_leaf_node(tree):\n",
    "            return tree\n",
    "\n",
    "        decision_node = next(iter(tree))\n",
    "        left_subtree, right_subtree = tree[decision_node]\n",
    "        left_subtree_index, right_subtree_index = 0, 1\n",
    "        leaf_node = Node(leaf=weakest_node.leaf, gini=weakest_node.gini)\n",
    "        \n",
    "        if weakest_node is decision_node:\n",
    "            tree = weakest_node\n",
    "        if self._is_in_dict(weakest_node, left_subtree) != None:\n",
    "            tree[decision_node][left_subtree_index] = leaf_node\n",
    "        if self._is_in_dict(weakest_node, right_subtree) != None:\n",
    "            tree[decision_node][right_subtree_index] = leaf_node\n",
    "\n",
    "        self._prune_tree(left_subtree, weakest_node)\n",
    "        self._prune_tree(right_subtree, weakest_node)\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def cost_complexity_pruning_path(self, X: pd.DataFrame, y: pd.Series):\n",
    "        tree = self._grow_tree(X, y)   # grow a full tree\n",
    "        tree_error_rate, _ = self._tree_error_rate_info(tree, [])\n",
    "        error_rates = [tree_error_rate]\n",
    "        ccp_alpha_list = [0.0]\n",
    "\n",
    "        while not self._is_leaf_node(tree):\n",
    "            initial_node = [None, np.inf]\n",
    "            weakest_node, ccp_alpha = self._find_weakest_node(tree, initial_node)\n",
    "            tree = self._prune_tree(tree, weakest_node)\n",
    "            tree_error_rate, _ = self._tree_error_rate_info(tree, [])\n",
    "\n",
    "            error_rates.append(tree_error_rate)\n",
    "            ccp_alpha_list.append(ccp_alpha)\n",
    "\n",
    "        return np.array(ccp_alpha_list), np.array(error_rates)\n",
    "\n",
    "    def _ccp_tree_error_rate(self, tree_error_rate, num_leaf_nodes):\n",
    "\n",
    "        return tree_error_rate + self.ccp_alpha*num_leaf_nodes   # regularization\n",
    "\n",
    "    def _optimal_tree(self, X, y):\n",
    "        tree = self._grow_tree(X, y) # grow a full tree\n",
    "        min_RT_alpha, final_tree = np.inf, None\n",
    "\n",
    "        while not self._is_leaf_node(tree):\n",
    "            RT, num_leaf_nodes = self._tree_error_rate_info(tree, [])\n",
    "            current_RT_alpha = self._ccp_tree_error_rate(RT, num_leaf_nodes)\n",
    "\n",
    "            if current_RT_alpha <= min_RT_alpha:\n",
    "                min_RT_alpha = current_RT_alpha\n",
    "                final_tree = deepcopy(tree)\n",
    "\n",
    "            initial_node = [None, np.inf]\n",
    "            weakest_node, _ = self._find_weakest_node(tree, initial_node)\n",
    "            tree = self._prune_tree(tree, weakest_node)\n",
    "\n",
    "        return final_tree\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        self.feature_importances_ = {}\n",
    "        self.tree = self._optimal_tree(X, y)\n",
    "        \n",
    "    def _traverse_tree(self, sample, tree):\n",
    "        if self._is_leaf_node(tree):\n",
    "            #leaf, *_ = tree.split()\n",
    "            leaf = tree.leaf\n",
    "            return leaf\n",
    "\n",
    "        decision_node = next(iter(tree))  # dict key\n",
    "        left_node, right_node = tree[decision_node]\n",
    "        feature = decision_node.feature\n",
    "        threshold = decision_node.threshold\n",
    "        feature_value = sample[feature]\n",
    "\n",
    "        if np.float64(feature_value) <= np.float64(threshold):\n",
    "            next_node = self._traverse_tree(sample, left_node)    # left_node\n",
    "        else:\n",
    "            next_node = self._traverse_tree(sample, right_node)   # right_node\n",
    "\n",
    "        return next_node\n",
    "\n",
    "    def predict(self, samples: pd.DataFrame):\n",
    "        # apply traverse_tree method for each row in a dataframe\n",
    "        results = samples.apply(self._traverse_tree, args=(self.tree,), axis=1)\n",
    "\n",
    "        return np.array(results.astype(self._y_dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0edfa5ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: y, Length: 150, dtype: int32\n",
      "{'x4': 0.6150738056897477, 'x3': 0.04270397208803007, 'x2': 0.008888888888888889}\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X, y = iris.data , iris.target\n",
    "df = pd.DataFrame(iris.data, columns=['x1', 'x2', 'x3', 'x4'])\n",
    "df['y'] = y\n",
    "\n",
    "Y = df['y']\n",
    "X = df[['x1', 'x2', 'x3', 'x4']]\n",
    "\n",
    "tree_classifier = DecisionTree()\n",
    "tree_classifier.fit(X, Y)\n",
    "#pprint(tree_classifier.tree, width=10)\n",
    "print(tree_classifier.feature_importances_)\n",
    "print(tree_classifier.predict(X))\n",
    "print(accuracy_score(tree_classifier.predict(X), Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
